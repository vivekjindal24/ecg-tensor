{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "307eef2cccb566c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Environment Setup\n",
   "id": "61cf2f534128517b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T04:40:14.283041Z",
     "start_time": "2025-11-10T04:40:02.222240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Environment Setup (robust torch import)\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Attempt torch import with graceful fallback message for DLL issues\n",
    "try:\n",
    "    import torch  # noqa: E402\n",
    "except OSError as e:\n",
    "    print(\"Torch import failed (likely CUDA DLL issue). Falling back instructions.\")\n",
    "    print(\"Original error:\\n\", e)\n",
    "    print(\"If you lack proper NVIDIA drivers or want CPU-only, reinstall with:\\n  pip install --force-reinstall --no-cache-dir torch --index-url https://download.pytorch.org/whl/cpu\")\n",
    "    # Retry CPU-only import if already installed\n",
    "    try:\n",
    "        import importlib\n",
    "        torch = importlib.import_module('torch')  # noqa: F401\n",
    "    except Exception:\n",
    "        raise\n",
    "\n",
    "import wfdb\n",
    "from scipy.signal import resample\n",
    "from sklearn.model_selection import train_test_split  # retained (may be unused now)\n",
    "import mlflow\n",
    "import fastapi  # ensure core library is available\n",
    "import uvicorn  # ensure core library is available\n",
    "\n",
    "_ = (os, sys, fastapi, uvicorn)\n",
    "\n",
    "ROOT = Path('.')\n",
    "ARTIFACTS_DIR = ROOT / 'artifacts'\n",
    "MODELS_DIR = ARTIFACTS_DIR / 'models'\n",
    "PROCESSED_DIR = ARTIFACTS_DIR / 'processed'\n",
    "MLFLOW_DIR = ARTIFACTS_DIR / 'mlflow'\n",
    "DATASET_DIR = ROOT / 'dataset'\n",
    "FIGURES_DIR = ROOT / 'figures'\n",
    "LOGS_DIR = ROOT / 'logs'\n",
    "\n",
    "for d in [ARTIFACTS_DIR, MODELS_DIR, PROCESSED_DIR, MLFLOW_DIR, DATASET_DIR, FIGURES_DIR, LOGS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cuda_available = torch.cuda.is_available() if hasattr(torch, 'cuda') else False\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "if cuda_available:\n",
    "    try:\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"GPU name unavailable: {e}\")\n",
    "\n",
    "print(\"Paths configured:\")\n",
    "print(f\"- ROOT:          {ROOT.resolve().as_posix()}\")\n",
    "print(f\"- DATASET_DIR:   {DATASET_DIR.resolve().as_posix()}\")\n",
    "print(f\"- ARTIFACTS_DIR: {ARTIFACTS_DIR.resolve().as_posix()}\")\n",
    "print(f\"  - MODELS_DIR:   {MODELS_DIR.resolve().as_posix()}\")\n",
    "print(f\"  - PROCESSED_DIR:{PROCESSED_DIR.resolve().as_posix()}\")\n",
    "print(f\"  - MLFLOW_DIR:   {MLFLOW_DIR.resolve().as_posix()}\")\n",
    "print(f\"- FIGURES_DIR:   {FIGURES_DIR.resolve().as_posix()}\")\n"
   ],
   "id": "80471af419e74588",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ecg-research\\.venv\\Lib\\site-packages\\mlflow\\utils\\requirements_utils.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources  # noqa: TID251\n",
      "D:\\ecg-research\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_config.py:383: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 2050\n",
      "Paths configured:\n",
      "- ROOT:          D:/ecg-research\n",
      "- DATASET_DIR:   D:/ecg-research/dataset\n",
      "- ARTIFACTS_DIR: D:/ecg-research/artifacts\n",
      "  - MODELS_DIR:   D:/ecg-research/artifacts/models\n",
      "  - PROCESSED_DIR:D:/ecg-research/artifacts/processed\n",
      "  - MLFLOW_DIR:   D:/ecg-research/artifacts/mlflow\n",
      "- FIGURES_DIR:   D:/ecg-research/figures\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preprocessing: Load, Normalize, and Split ECG Datasets\n",
   "id": "b74dddfec163692b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T13:14:15.493950Z",
     "start_time": "2025-11-10T13:14:10.301005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocessing (memory-safe streaming approach)\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import resample  # added: ensure resample available if cell runs first\n",
    "import pandas as pd\n",
    "import numpy as np  # added: ensure np available if cell runs first\n",
    "import wfdb  # added: ensure wfdb available if cell runs first\n",
    "import torch  # ensure torch is available here as well\n",
    "from pathlib import Path as _PathGuard\n",
    "from pathlib import Path  # added: Path symbol used below\n",
    "\n",
    "# Safety: rehydrate core paths if this cell runs before Environment Setup\n",
    "try:\n",
    "    ROOT\n",
    "except NameError:\n",
    "    ROOT = _PathGuard('.')\n",
    "\n",
    "ARTIFACTS_DIR = ARTIFACTS_DIR if 'ARTIFACTS_DIR' in globals() else ROOT / 'artifacts'\n",
    "PROCESSED_DIR = PROCESSED_DIR if 'PROCESSED_DIR' in globals() else ARTIFACTS_DIR / 'processed'\n",
    "DATASET_DIR = DATASET_DIR if 'DATASET_DIR' in globals() else ROOT / 'dataset'\n",
    "FIGURES_DIR = FIGURES_DIR if 'FIGURES_DIR' in globals() else ROOT / 'figures'\n",
    "LOGS_DIR = LOGS_DIR if 'LOGS_DIR' in globals() else ROOT / 'logs'\n",
    "for _d in [ARTIFACTS_DIR, PROCESSED_DIR, DATASET_DIR, FIGURES_DIR, LOGS_DIR]:\n",
    "    _PathGuard(_d).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TARGET_FS = 500\n",
    "TARGET_SAMPLES = 5000\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Unified label mapping setup\n",
    "UNIFIED_CSV = LOGS_DIR / 'unified_label_mapping.csv'\n",
    "LABEL_ORDER = ['MI', 'AF', 'BBB', 'NORM', 'OTHER']\n",
    "LABEL_TO_INT: Dict[str, int] = {name: idx for idx, name in enumerate(LABEL_ORDER)}\n",
    "\n",
    "# Build a robust mapping index from unified CSV\n",
    "mapping_index: Dict[str, Dict[str, str]] = {}\n",
    "if UNIFIED_CSV.exists():\n",
    "    umap_df = pd.read_csv(UNIFIED_CSV, dtype=str)\n",
    "    umap_df.columns = [c.strip() for c in umap_df.columns]\n",
    "    required_cols = {'dataset', 'record_id', 'mapped_label'}\n",
    "    missing = required_cols - set(umap_df.columns)\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Unified mapping missing columns: {missing}\")\n",
    "    for _, row in umap_df.iterrows():\n",
    "        ds = str(row['dataset']).strip()\n",
    "        rid = str(row['record_id']).strip()\n",
    "        lab = str(row['mapped_label']).strip().upper()\n",
    "        if not ds or not rid:\n",
    "            continue\n",
    "        if ds not in mapping_index:\n",
    "            mapping_index[ds] = {}\n",
    "        rid_norm = rid.replace('\\\\', '/').strip('/')\n",
    "        mapping_index[ds][rid_norm] = lab\n",
    "        try:\n",
    "            p = Path(rid_norm)\n",
    "            mapping_index[ds][p.name] = lab\n",
    "            if len(p.parts) >= 2:\n",
    "                mapping_index[ds]['/'.join(p.parts[-2:])] = lab\n",
    "            if len(p.parts) >= 2 and p.parts[0] == ds:\n",
    "                mapping_index[ds]['/'.join(p.parts[1:])] = lab\n",
    "        except Exception:\n",
    "            pass\n",
    "else:\n",
    "    print(f\"WARNING: {UNIFIED_CSV.as_posix()} not found. Unmapped records will default to OTHER.\")\n",
    "\n",
    "print(\"Scanning dataset directory for WFDB headers (.hea)...\")\n",
    "hea_files = sorted(DATASET_DIR.rglob('*.hea'))\n",
    "mat_files = sorted(DATASET_DIR.rglob('*.mat')) if not hea_files else []\n",
    "if not hea_files and not mat_files:\n",
    "    raise RuntimeError(f\"No supported ECG files found under {DATASET_DIR} (expected .hea or .mat)\")\n",
    "\n",
    "# --- Utility functions ---\n",
    "\n",
    "def zscore_normalize(x: np.ndarray) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    m = float(x.mean())\n",
    "    s = float(x.std())\n",
    "    if s < 1e-8:\n",
    "        s = 1.0\n",
    "    return (x - m) / s\n",
    "\n",
    "def pad_or_truncate(x: np.ndarray, length: int) -> np.ndarray:\n",
    "    if x.size < length:\n",
    "        return np.pad(x, (0, length - x.size), mode='constant')\n",
    "    if x.size > length:\n",
    "        return x[:length]\n",
    "    return x\n",
    "\n",
    "def _wfdb_read(record_header_path: Path) -> Tuple[np.ndarray, float]:\n",
    "    record_path = record_header_path.with_suffix('')\n",
    "    try:\n",
    "        sig, fields = wfdb.rdsamp(str(record_path))\n",
    "        fs = float(fields.get('fs', TARGET_FS))\n",
    "        if sig.ndim == 2:\n",
    "            sig_1d = sig[:, 0]\n",
    "        else:\n",
    "            sig_1d = sig.reshape(-1)\n",
    "        return sig_1d.astype(np.float32), fs\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"WFDB read failed for {record_header_path.name}: {e}\")\n",
    "\n",
    "def _mat_read(mat_path: Path) -> Tuple[np.ndarray, Optional[float]]:\n",
    "    mat = loadmat(mat_path)\n",
    "    for key in ('val', 'data', 'signal'):\n",
    "        if key in mat:\n",
    "            arr = np.asarray(mat[key])\n",
    "            break\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unexpected MAT structure for {mat_path.name}\")\n",
    "    if arr.ndim == 2:\n",
    "        if arr.shape[0] > 1:\n",
    "            arr = arr[0]\n",
    "        else:\n",
    "            arr = arr.reshape(-1)\n",
    "    elif arr.ndim > 2:\n",
    "        arr = arr.reshape(-1)\n",
    "    arr = np.asarray(arr, dtype=np.float32)\n",
    "    fs = None\n",
    "    return arr, fs\n",
    "\n",
    "def _lookup_mapped_label(path: Path) -> str:\n",
    "    rel = path.relative_to(DATASET_DIR).with_suffix('')\n",
    "    parts = rel.parts\n",
    "    if not parts:\n",
    "        return 'OTHER'\n",
    "    ds = parts[0]\n",
    "    key_full = rel.as_posix()\n",
    "    key_wo_ds = '/'.join(parts[1:]) if len(parts) > 1 else ''\n",
    "    key_last2 = '/'.join(parts[-2:]) if len(parts) >= 2 else ''\n",
    "    key_name = rel.name\n",
    "    candidates = [key_full, key_wo_ds, key_last2, key_name]\n",
    "    index = mapping_index.get(ds, {})\n",
    "    for k in candidates:\n",
    "        if k and k in index:\n",
    "            lab = index[k]\n",
    "            return lab if lab in LABEL_TO_INT else 'OTHER'\n",
    "    if ds == 'CinC_2017_AFDB':\n",
    "        if len(parts) >= 3 and parts[1] in {'training', 'validation', 'test'}:\n",
    "            alt = '/'.join(parts[2:])\n",
    "            if alt in index:\n",
    "                lab = index[alt]\n",
    "                return lab if lab in LABEL_TO_INT else 'OTHER'\n",
    "    return 'OTHER'\n",
    "\n",
    "def _resample_if_needed(x: np.ndarray, fs: Optional[float]) -> np.ndarray:\n",
    "    if fs is None or np.isclose(fs, TARGET_FS):\n",
    "        return x\n",
    "    new_len = int(round(x.size * TARGET_FS / float(fs)))\n",
    "    return resample(x, new_len)\n",
    "\n",
    "# --- Streaming save implementation ---\n",
    "RECORDS_DIR = PROCESSED_DIR / 'records'\n",
    "RECORDS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "manifest: List[Dict[str, str]] = []\n",
    "from collections import Counter, defaultdict\n",
    "class_counts = Counter()\n",
    "\n",
    "source_files = hea_files if hea_files else mat_files\n",
    "source_type = 'WFDB' if hea_files else 'MAT'\n",
    "print(f\"Processing {len(source_files)} {source_type} record(s) with streaming save...\")\n",
    "\n",
    "skipped = 0\n",
    "for i, path in enumerate(source_files):\n",
    "    try:\n",
    "        if source_type == 'WFDB':\n",
    "            raw, fs = _wfdb_read(path)\n",
    "        else:\n",
    "            raw, fs = _mat_read(path)\n",
    "        raw = _resample_if_needed(raw, fs)\n",
    "        raw = zscore_normalize(raw)\n",
    "        raw = pad_or_truncate(raw, TARGET_SAMPLES)\n",
    "        label_name = _lookup_mapped_label(path)\n",
    "        label_int = LABEL_TO_INT.get(label_name, LABEL_TO_INT['OTHER'])\n",
    "        # Construct record id without extension (sanitized)\n",
    "        rel = path.relative_to(DATASET_DIR).with_suffix('')\n",
    "        record_id = rel.as_posix().replace('/', '__')  # flatten hierarchy into filename\n",
    "        out_file = RECORDS_DIR / f\"{record_id}.npz\"\n",
    "        np.savez_compressed(out_file, signal=raw.astype(np.float32), label=np.int64(label_int))\n",
    "        manifest.append({'path': f\"records/{out_file.name}\", 'label': int(label_int)})\n",
    "        class_counts[label_int] += 1\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Saved {i+1}/{len(source_files)} records...\")\n",
    "    except Exception as e:\n",
    "        skipped += 1\n",
    "        if skipped < 25:  # limit verbose errors\n",
    "            print(f\"Skipping {path.name}: {e}\")\n",
    "\n",
    "if skipped:\n",
    "    print(f\"Skipped {skipped} record(s) due to read errors.\")\n",
    "\n",
    "if not manifest:\n",
    "    raise RuntimeError(\"No records successfully processed; aborting streaming pipeline.\")\n",
    "\n",
    "# Stratified split (80/10/10) using per-class grouping for balanced distribution\n",
    "rng = np.random.default_rng(seed=42)\n",
    "by_class = defaultdict(list)\n",
    "for entry in manifest:\n",
    "    by_class[entry['label']].append(entry)\n",
    "\n",
    "train_paths, val_paths, test_paths = [], [], []\n",
    "for label_val, items in by_class.items():\n",
    "    rng.shuffle(items)\n",
    "    n = len(items)\n",
    "    n_train = int(round(0.80 * n))\n",
    "    n_val = int(round(0.10 * n))\n",
    "    n_test = n - n_train - n_val\n",
    "    # Adjust rounding if off by one due to round() usage\n",
    "    if n_test < 0:\n",
    "        n_test = 0\n",
    "        while n_train + n_val > n:\n",
    "            n_train -= 1\n",
    "    train_items = items[:n_train]\n",
    "    val_items = items[n_train:n_train + n_val]\n",
    "    test_items = items[n_train + n_val:]\n",
    "    train_paths.extend([x['path'] for x in train_items])\n",
    "    val_paths.extend([x['path'] for x in val_items])\n",
    "    test_paths.extend([x['path'] for x in test_items])\n",
    "\n",
    "splits = {\n",
    "    'timestamp': datetime.now(timezone.utc).isoformat(timespec='seconds'),\n",
    "    'label_order': LABEL_ORDER,\n",
    "    'label_to_int': LABEL_TO_INT,\n",
    "    'counts': {\n",
    "        'train': len(train_paths),\n",
    "        'val': len(val_paths),\n",
    "        'test': len(test_paths)\n",
    "    },\n",
    "    'paths': {\n",
    "        'train': train_paths,\n",
    "        'val': val_paths,\n",
    "        'test': test_paths\n",
    "    },\n",
    "    'class_counts': {int(k): int(v) for k, v in class_counts.items()}\n",
    "}\n",
    "(PROCESSED_DIR / 'splits.json').write_text(json.dumps(splits, indent=2), encoding='utf-8')\n",
    "\n",
    "# Save label names and label map (unchanged interface for downstream)\n",
    "np.save(PROCESSED_DIR / 'labels.npy', np.array(LABEL_ORDER, dtype=object))\n",
    "label_map = {\n",
    "    'label_to_int': LABEL_TO_INT,\n",
    "    'int_to_label': {str(v): k for k, v in LABEL_TO_INT.items()}\n",
    "}\n",
    "(PROCESSED_DIR / 'label_map.json').write_text(json.dumps(label_map, indent=2), encoding='utf-8')\n",
    "\n",
    "print(\"Per-class counts:\")\n",
    "for idx, name in enumerate(LABEL_ORDER):\n",
    "    print(f\"  {idx}={name}: {class_counts.get(idx, 0)}\")\n",
    "print(f\"Total records saved: {len(manifest)}\")\n",
    "print(\"Chunked preprocessing completed; all signals saved individually and memory-safe.\")\n",
    "print(\"Preprocessing with unified labels completed successfully.\")\n",
    "\n",
    "# NOTE: Previous in-memory stacking removed for OOM safety.\n",
    "# np.stack(signals)  # <-- removed / commented out intentionally.\n"
   ],
   "id": "5ab57c93abd886",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning dataset directory for WFDB headers (.hea)...\n",
      "Processing 108520 WFDB record(s) with streaming save...\n",
      "Skipping JS00001.hea: WFDB read failed for JS00001.hea: name 'wfdb' is not defined\n",
      "Skipping JS00002.hea: WFDB read failed for JS00002.hea: name 'wfdb' is not defined\n",
      "Skipping JS00004.hea: WFDB read failed for JS00004.hea: name 'wfdb' is not defined\n",
      "Skipping JS00005.hea: WFDB read failed for JS00005.hea: name 'wfdb' is not defined\n",
      "Skipping JS00006.hea: WFDB read failed for JS00006.hea: name 'wfdb' is not defined\n",
      "Skipping JS00007.hea: WFDB read failed for JS00007.hea: name 'wfdb' is not defined\n",
      "Skipping JS00008.hea: WFDB read failed for JS00008.hea: name 'wfdb' is not defined\n",
      "Skipping JS00009.hea: WFDB read failed for JS00009.hea: name 'wfdb' is not defined\n",
      "Skipping JS00010.hea: WFDB read failed for JS00010.hea: name 'wfdb' is not defined\n",
      "Skipping JS00011.hea: WFDB read failed for JS00011.hea: name 'wfdb' is not defined\n",
      "Skipping JS00012.hea: WFDB read failed for JS00012.hea: name 'wfdb' is not defined\n",
      "Skipping JS00013.hea: WFDB read failed for JS00013.hea: name 'wfdb' is not defined\n",
      "Skipping JS00014.hea: WFDB read failed for JS00014.hea: name 'wfdb' is not defined\n",
      "Skipping JS00015.hea: WFDB read failed for JS00015.hea: name 'wfdb' is not defined\n",
      "Skipping JS00016.hea: WFDB read failed for JS00016.hea: name 'wfdb' is not defined\n",
      "Skipping JS00017.hea: WFDB read failed for JS00017.hea: name 'wfdb' is not defined\n",
      "Skipping JS00018.hea: WFDB read failed for JS00018.hea: name 'wfdb' is not defined\n",
      "Skipping JS00019.hea: WFDB read failed for JS00019.hea: name 'wfdb' is not defined\n",
      "Skipping JS00020.hea: WFDB read failed for JS00020.hea: name 'wfdb' is not defined\n",
      "Skipping JS00021.hea: WFDB read failed for JS00021.hea: name 'wfdb' is not defined\n",
      "Skipping JS00022.hea: WFDB read failed for JS00022.hea: name 'wfdb' is not defined\n",
      "Skipping JS00023.hea: WFDB read failed for JS00023.hea: name 'wfdb' is not defined\n",
      "Skipping JS00024.hea: WFDB read failed for JS00024.hea: name 'wfdb' is not defined\n",
      "Skipping JS00025.hea: WFDB read failed for JS00025.hea: name 'wfdb' is not defined\n",
      "Skipped 108520 record(s) due to read errors.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No records successfully processed; aborting streaming pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 189\u001B[39m\n\u001B[32m    186\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mSkipped \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mskipped\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m record(s) due to read errors.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    188\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m manifest:\n\u001B[32m--> \u001B[39m\u001B[32m189\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mNo records successfully processed; aborting streaming pipeline.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    191\u001B[39m \u001B[38;5;66;03m# Stratified split (80/10/10) using per-class grouping for balanced distribution\u001B[39;00m\n\u001B[32m    192\u001B[39m rng = np.random.default_rng(seed=\u001B[32m42\u001B[39m)\n",
      "\u001B[31mRuntimeError\u001B[39m: No records successfully processed; aborting streaming pipeline."
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Training and Experiment Logging\n",
   "id": "4bfe9bf92e5aa3a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-10T09:07:25.778186Z",
     "start_time": "2025-11-10T09:01:56.174973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model Training with MLflow (adapted for lazy per-record loading)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class RecordDataset(Dataset):\n",
    "    def __init__(self, split: str, splits_path: Path, processed_root: Path):\n",
    "        payload = json.loads(splits_path.read_text())\n",
    "        if split not in payload['paths']:\n",
    "            raise ValueError(f\"Split '{split}' not found in splits.json\")\n",
    "        self.paths = [processed_root / p for p in payload['paths'][split]]\n",
    "        self.label_to_int = payload['label_to_int']\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.paths)\n",
    "    def __getitem__(self, idx: int):\n",
    "        p = self.paths[idx]\n",
    "        data = np.load(p)\n",
    "        sig = data['signal'].astype(np.float32)  # (5000,)\n",
    "        lab = int(data['label'])\n",
    "        x = torch.from_numpy(sig).float().unsqueeze(0).unsqueeze(0)  # (1,1,5000)\n",
    "        return x, lab\n",
    "\n",
    "class SmallNet(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(1, 7), padding=(0, 3)),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((1, 2)),\n",
    "            nn.Conv2d(16, 32, kernel_size=(1, 5), padding=(0, 2)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((1, 2))\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, 1, TARGET_SAMPLES)\n",
    "            flattened = self.features(dummy).view(1, -1).size(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flattened, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.classifier(self.features(x))\n",
    "\n",
    "splits_file = PROCESSED_DIR / 'splits.json'\n",
    "labels_file = PROCESSED_DIR / 'labels.npy'\n",
    "if not splits_file.exists():\n",
    "    raise FileNotFoundError('splits.json not found. Run preprocessing cell first.')\n",
    "label_names = np.load(labels_file, allow_pickle=True).tolist()\n",
    "num_classes = len(label_names)\n",
    "\n",
    "train_ds = RecordDataset('train', splits_file, PROCESSED_DIR)\n",
    "val_ds = RecordDataset('val', splits_file, PROCESSED_DIR)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 8\n",
    "learning_rate = 1e-3\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = SmallNet(num_classes=num_classes).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "tracking_uri = f\"sqlite:///{(MLFLOW_DIR / 'mlflow.db').as_posix()}\"\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "mlflow.set_experiment('ECG_Tensor_Research')\n",
    "\n",
    "\n",
    "def evaluate(loader: DataLoader) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_loss += loss.item() * xb.size(0)\n",
    "            correct += int(np.count_nonzero(preds.cpu().numpy() == yb.cpu().numpy()))\n",
    "            total += xb.size(0)\n",
    "    return (total_loss / max(total, 1)), (correct / max(total, 1))\n",
    "\n",
    "history = []\n",
    "best_val_loss = float('inf')\n",
    "best_state = None\n",
    "best_epoch = -1\n",
    "\n",
    "with mlflow.start_run(run_name='notebook-training'):\n",
    "    mlflow.log_params({\n",
    "        'batch_size': batch_size,\n",
    "        'epochs': epochs,\n",
    "        'learning_rate': learning_rate,\n",
    "        'architecture': 'SmallNet-2xConv2D',\n",
    "        'streaming_preprocessing': True\n",
    "    })\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            yb = yb.to(DEVICE)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running += loss.item() * xb.size(0)\n",
    "        train_loss = running / len(train_ds)\n",
    "        val_loss, val_acc = evaluate(val_loader)\n",
    "        history.append({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss, 'val_acc': val_acc})\n",
    "        mlflow.log_metric('train_loss', train_loss, step=epoch)\n",
    "        mlflow.log_metric('val_loss', val_loss, step=epoch)\n",
    "        mlflow.log_metric('val_accuracy', val_acc, step=epoch)\n",
    "        print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | val_acc={val_acc:.3f}\")\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            best_epoch = epoch\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "        print(f\"Loaded best model from epoch {best_epoch}\")\n",
    "    best_model_path = MODELS_DIR / 'best_model.pt'\n",
    "    torch.save({\n",
    "        'state_dict': model.state_dict(),\n",
    "        'labels': label_names,\n",
    "        'config': {\n",
    "            'target_fs': TARGET_FS,\n",
    "            'target_samples': TARGET_SAMPLES,\n",
    "            'architecture': 'SmallNet-2xConv2D',\n",
    "            'streaming_preprocessing': True\n",
    "        }\n",
    "    }, best_model_path)\n",
    "    mlflow.log_artifact(str(best_model_path), artifact_path='models')\n",
    "    history_path = MODELS_DIR / 'training_history.json'\n",
    "    history_path.write_text(json.dumps(history, indent=2), encoding='utf-8')\n",
    "    mlflow.log_artifact(str(history_path), artifact_path='history')\n",
    "\n",
    "print(\"Training finished.\")\n"
   ],
   "id": "834fdb2ff1951cec",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/10 14:32:19 INFO mlflow.tracking.fluent: Experiment with name 'ECG_Tensor_Research' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=5.2410 | val_loss=4.6069 | val_acc=0.111\n",
      "Epoch 02 | train_loss=4.6908 | val_loss=4.4625 | val_acc=0.119\n",
      "Epoch 03 | train_loss=4.5052 | val_loss=4.3770 | val_acc=0.123\n",
      "Epoch 04 | train_loss=4.4075 | val_loss=4.3645 | val_acc=0.124\n",
      "Epoch 05 | train_loss=4.3206 | val_loss=4.3288 | val_acc=0.124\n",
      "Epoch 06 | train_loss=4.2411 | val_loss=4.3419 | val_acc=0.126\n",
      "Epoch 07 | train_loss=4.1952 | val_loss=4.6939 | val_acc=0.114\n",
      "Epoch 08 | train_loss=4.1296 | val_loss=4.3063 | val_acc=0.147\n",
      "Loaded best model from epoch 8\n",
      "Training finished.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluation: Metrics and Diagnostic Plots\n",
   "id": "1972bb81efe6bbdb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluation and Visualization (lazy record loading)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "splits_file = PROCESSED_DIR / 'splits.json'\n",
    "label_names = np.load(PROCESSED_DIR / 'labels.npy', allow_pickle=True).tolist()\n",
    "num_classes = len(label_names)\n",
    "\n",
    "class TestRecordDataset(Dataset):\n",
    "    def __init__(self, split: str, splits_path: Path, processed_root: Path):\n",
    "        payload = json.loads(splits_path.read_text())\n",
    "        self.paths = [processed_root / p for p in payload['paths'][split]]\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    def __getitem__(self, i: int):\n",
    "        p = self.paths[i]\n",
    "        data = np.load(p)\n",
    "        sig = data['signal'].astype(np.float32)\n",
    "        lab = int(data['label'])\n",
    "        x = torch.from_numpy(sig).float().unsqueeze(0).unsqueeze(0)\n",
    "        return x, lab\n",
    "\n",
    "class _EvalSmallNet(SmallNet):\n",
    "    pass\n",
    "\n",
    "\n",
    "def _load_best_model() -> Tuple[torch.nn.Module, list]:\n",
    "    ckpt_path = MODELS_DIR / 'best_model.pt'\n",
    "    if not ckpt_path.exists():\n",
    "        raise FileNotFoundError('best_model.pt not found. Train the model first.')\n",
    "    payload = torch.load(ckpt_path, map_location=DEVICE)\n",
    "    labels = payload.get('labels')\n",
    "    model = SmallNet(num_classes=len(labels))\n",
    "    model.load_state_dict(payload['state_dict'])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model, labels\n",
    "\n",
    "model, label_names = _load_best_model()\n",
    "\n",
    "test_ds = TestRecordDataset('test', splits_file, PROCESSED_DIR)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "all_logits = []\n",
    "all_targets = []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        logits = model(xb)\n",
    "        all_logits.append(logits.cpu().numpy())\n",
    "        all_targets.append(yb.numpy())\n",
    "\n",
    "logits = np.concatenate(all_logits, axis=0)\n",
    "y_true = np.concatenate(all_targets, axis=0)\n",
    "y_prob = torch.softmax(torch.from_numpy(logits), dim=1).numpy()\n",
    "y_pred = y_prob.argmax(axis=1)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "try:\n",
    "    if num_classes == 2:\n",
    "        auc = roc_auc_score(y_true, y_prob[:, 1])\n",
    "    else:\n",
    "        y_true_oh = label_binarize(y_true, classes=list(range(num_classes)))\n",
    "        auc = roc_auc_score(y_true_oh, y_prob, average='macro', multi_class='ovr')\n",
    "except Exception:\n",
    "    auc = float('nan')\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "if num_classes == 2:\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1])\n",
    "    plt.plot(fpr, tpr, label=f'AUC={auc:.3f}')\n",
    "else:\n",
    "    fpr_grid = np.linspace(0.0, 1.0, 1001)\n",
    "    tprs = []\n",
    "    for c in range(num_classes):\n",
    "        try:\n",
    "            y_true_c = np.asarray(y_true == c, dtype=int)\n",
    "            fpr_c, tpr_c, _ = roc_curve(y_true_c, y_prob[:, c])\n",
    "            tpr_interp = np.interp(fpr_grid, fpr_c, tpr_c)\n",
    "            tprs.append(tpr_interp)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if tprs:\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        plt.plot(fpr_grid, mean_tpr, label=f'Macro AUC={auc:.3f}')\n",
    "    else:\n",
    "        plt.plot([0, 1], [0, 1], 'k--', label='No ROC')\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "roc_path = FIGURES_DIR / 'roc.png'\n",
    "plt.tight_layout()\n",
    "plt.savefig(roc_path, dpi=150)\n",
    "plt.close()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "Disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)\n",
    "Disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "cm_path = FIGURES_DIR / 'confusion_matrix.png'\n",
    "plt.tight_layout()\n",
    "plt.savefig(cm_path, dpi=150)\n",
    "plt.close()\n",
    "\n",
    "try:\n",
    "    if mlflow.active_run():\n",
    "        mlflow.end_run()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "with mlflow.start_run(run_name='evaluation'):\n",
    "    mlflow.log_metric('test_accuracy', float(acc))\n",
    "    if not np.isnan(auc):\n",
    "        mlflow.log_metric('test_auroc', float(auc))\n",
    "    mlflow.log_metric('test_f1_macro', float(f1))\n",
    "    mlflow.log_artifact(str(roc_path), artifact_path='figures')\n",
    "    mlflow.log_artifact(str(cm_path), artifact_path='figures')\n",
    "\n",
    "print(\"Evaluation summary:\")\n",
    "print(f\"- Accuracy: {acc:.4f}\")\n",
    "print(f\"- AUROC:   {auc:.4f}\")\n",
    "print(f\"- F1:      {f1:.4f}\")\n"
   ],
   "id": "80430b105e839c66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Serving via FastAPI\n",
   "id": "609a8766785eefb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Serving API (do not launch server from within the notebook)\n",
    "import io\n",
    "from fastapi import FastAPI, UploadFile, File\n",
    "from fastapi.responses import JSONResponse\n",
    "from scipy.signal import resample  # added: ensure resample available here, too\n",
    "\n",
    "MODEL_CACHE = {}\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_path: Optional[Path] = None):\n",
    "    if checkpoint_path is None:\n",
    "        candidates = sorted(MODELS_DIR.glob('*.pt'), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "        if not candidates:\n",
    "            raise FileNotFoundError('No checkpoint available. Train the model before serving.')\n",
    "        checkpoint_path = candidates[0]\n",
    "    payload = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "    labels = payload.get('labels')\n",
    "    model = SmallNet(num_classes=len(labels))\n",
    "    model.load_state_dict(payload['state_dict'])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model, labels, checkpoint_path\n",
    "\n",
    "\n",
    "def prepare_for_inference(arr: np.ndarray) -> torch.Tensor:\n",
    "    arr = np.asarray(arr).astype(np.float32)\n",
    "    if arr.ndim > 1:\n",
    "        arr = arr.reshape(-1)\n",
    "    if arr.size != TARGET_SAMPLES:\n",
    "        arr = resample(arr, TARGET_SAMPLES)\n",
    "    m = float(arr.mean())\n",
    "    s = float(arr.std()) or 1.0\n",
    "    arr = (arr - m) / s\n",
    "    return torch.from_numpy(arr).float().unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "\n",
    "def predict_signal(input_data: np.ndarray) -> dict:\n",
    "    if 'model' not in MODEL_CACHE:\n",
    "        model, labels, ckpt = load_checkpoint()\n",
    "        MODEL_CACHE['model'] = model\n",
    "        MODEL_CACHE['labels'] = labels\n",
    "        MODEL_CACHE['ckpt'] = ckpt\n",
    "        print(f\"Loaded checkpoint {ckpt.name} for serving.\")\n",
    "    model = MODEL_CACHE['model']\n",
    "    labels = MODEL_CACHE['labels']\n",
    "    xb = prepare_for_inference(input_data)\n",
    "    with torch.no_grad():\n",
    "        logits = model(xb)\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "    top = int(np.argmax(probs))\n",
    "    return {\n",
    "        'predicted_class': labels[top],\n",
    "        'confidence': float(probs[top]),\n",
    "        'probabilities': {label: float(p) for label, p in zip(labels, probs)}\n",
    "    }\n",
    "\n",
    "app = FastAPI(title='ECG Tensor Inference API')\n",
    "\n",
    "@app.post('/predict')\n",
    "async def predict_endpoint(file: UploadFile = File(...)):\n",
    "    payload = await file.read()\n",
    "    buffer = io.BytesIO(payload)\n",
    "    suffix = Path(file.filename).suffix.lower()\n",
    "    if suffix == '.npy':\n",
    "        buffer.seek(0)\n",
    "        arr = np.load(buffer, allow_pickle=True)\n",
    "    else:  # assume CSV\n",
    "        buffer.seek(0)\n",
    "        arr = np.loadtxt(buffer, delimiter=',')\n",
    "    result = predict_signal(arr)\n",
    "    return JSONResponse(result)\n",
    "\n",
    "# Run this in terminal using uvicorn serve:app --reload\n"
   ],
   "id": "d27339240e7f6c46",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "language": "markdown"
   },
   "source": [
    "### 6. PowerShell Execution Instructions\n",
    "\n",
    "```powershell\n",
    "# (Optional) Create and activate a virtual environment\n",
    "python -m venv .venv\n",
    ".\\.venv\\Scripts\\Activate.ps1\n",
    "\n",
    "# Install dependencies\n",
    "pip install -U pip\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Run preprocessing cell (streaming, memory-safe)\n",
    "# Train model\n",
    "# Evaluate and generate figures\n",
    "\n",
    "# Start MLflow UI (optional)\n",
    "mlflow ui --backend-store-uri sqlite:///artifacts/mlflow/mlflow.db --default-artifact-root ./artifacts --host 127.0.0.1 --port 5000\n",
    "\n",
    "# Serve the API locally\n",
    "uvicorn ecg_tensor_pipeline:app --reload\n",
    "```\n"
   ],
   "id": "2e2907cc4baf3a27"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECG Research",
   "language": "python",
   "name": "ecg-research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
